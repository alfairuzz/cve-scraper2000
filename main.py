import os
import time
import logging
from io import BytesIO

import pandas as pd
import qrcode
import streamlit as st
import streamlit_shadcn_ui as ui
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType

from parse_apple_link import get_apple_details
from parse_google_chrome_link import get_google_chrome_details
from parse_oracle_link import get_oracle_details
from parse_sap_link import get_sap_details
from parse_fortinet_link import get_fortinet_details, get_complete_fortinet_details


# Set up logging
logging.basicConfig(level=logging.INFO)

# ------------------- Streamlit UI Setup -------------------

st.markdown(
    "<h1>Webscraper UI <small style='font-size: 12px;'>by maf</small></h1>",
    unsafe_allow_html=True
)
ui.badges(
    badge_list=[("GOI", "default"), ("Annex A", "secondary")],
    class_name="flex gap-2",
    key="main_badges1"
)

st.info('Currently available for the following products', icon="‚ÑπÔ∏è")

apple_url = "https://support.apple.com/en-sg/100100"
google_url = "https://chromereleases.googleblog.com"
oracle_url = "https://www.oracle.com/sg/security-alerts/"
sap_url = "https://support.sap.com/en/my-support/knowledge-base/security-notes-news.html?anchorId=section_370125364"
fortinet_url = "https://www.fortiguard.com/psirt?product=FortiClientMac,FortiNDR,FortiNAC,FortiWLC,FortiSIEM,FortiWAN,FortiADCManager,FortiSwitch,FortiDDoS-CM,FortiMail,FortiSandbox,FortiSwitchManager,FortiAP-U,FortiRecorder,FortiOS-6K7K,FortiAP-W2,FortiWeb,FortiClientAndroid,FortiAP-C,FortiAnalyzer,FortiAP-S,FortiDeceptor,FortiExtender,FortiEDR,FortiWLM,FortiProxy,FortiAuthenticator,FortiTester,FortiManager,FortiDDoS,FortiClientWindows,FortiDDoS-F,FortiClientiOS,FortiAnalyzer-BigData,FortiADC,FortiGuard,FortiWebManager,FortiVoiceEnterprise,FortiClientEMS,FortiOS,FortiSOAR,FortiAP,FortiClientLinux,FortiPortal"

f"""
1) Apple (iOS, iPadOS & macOS) - [Link Here]({apple_url})
2) Google (Stable Channel Update for Desktop) - [Link Here]({google_url})
3) Oracle (Critical Patch Updates) - [Link Here]({oracle_url})
4) SAP (Security Patch Day) - [Link Here]({sap_url})
5) Fortiguard (PSIRT Advisory) - [Link Here]({fortinet_url})
"""

# Sidebar Information
st.sidebar.markdown("<h1 style='font-size:28px;'>‚òï About</h1>", unsafe_allow_html=True)
st.sidebar.markdown(
    "Webscraper UI is an application designed to extract key vulnerability details, "
    "such as CVE information, affected products, and CVE base scores, from specified "
    "product websites. This tool simplifies the process of gathering security-related "
    "data for analysis."
)

st.sidebar.markdown("<h1 style='font-size:28px;'>üöÄ Usage</h1>", unsafe_allow_html=True)
st.sidebar.markdown(
    "Simply enter the URL into the search bar, and the application will extract and "
    "summarize the relevant information into a downloadable .xlsx file."
)

st.header("üîç Search", divider=True)

# ------------------- Input Field -------------------

url = st.text_input("Enter a Website URL:")

# ------------------- Helper Functions -------------------

@st.cache_data
def convert_df_to_excel(df):
    """
    Converts a DataFrame to an Excel file in memory.

    Parameters:
    df (pd.DataFrame): The DataFrame to convert.

    Returns:
    BytesIO: A BytesIO stream containing the Excel file.
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False)
    output.seek(0)
    return output

def convert_dfs_to_excel(dfs, sheet_names):
    """
    Converts multiple DataFrames to an Excel file in memory with specified sheet names.

    Parameters:
    dfs (list of pd.DataFrame): The list of DataFrames to convert.
    sheet_names (list of str): The list of sheet names corresponding to each DataFrame.

    Returns:
    BytesIO: A BytesIO stream containing the Excel file.
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        for df, sheet_name in zip(dfs, sheet_names):
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    output.seek(0)
    return output

def generate_unique_qr_codes(df, url_column, qr_code_column):
    """
    Generates QR codes for unique URLs in the DataFrame and stores them as bytes.

    Parameters:
    df (pd.DataFrame): The DataFrame containing the URLs.
    url_column (str): The name of the column containing the URLs.
    qr_code_column (str): The name of the column to store the QR code bytes.

    Returns:
    pd.DataFrame: The DataFrame with a new column containing the QR code bytes.
    """
    unique_urls = set()
    df[qr_code_column] = None

    for index, row in df.iterrows():
        url = row[url_column]
        if url and url not in unique_urls:
            unique_urls.add(url)
            qr_img = qrcode.make(url)
            img_byte_arr = BytesIO()
            qr_img.save(img_byte_arr, format='PNG')
            img_byte_arr.seek(0)
            df.at[index, qr_code_column] = img_byte_arr

    return df

def convert_df_to_excel_with_qr(df, qr_code_column):
    """
    Converts a DataFrame to an Excel file with QR code images embedded.

    Parameters:
    df (pd.DataFrame): The DataFrame to convert.
    qr_code_column (str): The name of the column containing QR code bytes.

    Returns:
    BytesIO: A BytesIO stream containing the Excel file.
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        # Write the DataFrame without the QR code column
        df_no_qr = df.drop(columns=[qr_code_column])
        df_no_qr.to_excel(writer, index=False, sheet_name='Sheet1')

        workbook = writer.book
        worksheet = writer.sheets['Sheet1']

        # Set column width for the QR code column
        worksheet.set_column('H:H', 15)  # Adjust as needed

        for index, row in df.iterrows():
            qr_code_bytes = row[qr_code_column]
            if qr_code_bytes:
                # Determine the cell to insert the QR code
                cell = f'H{index + 2}'  # Adjust based on the row number
                # Insert image from bytes
                worksheet.insert_image(
                    cell,
                    '',
                    {'image_data': qr_code_bytes, 'x_scale': 0.5, 'y_scale': 0.5}
                )

    output.seek(0)
    return output

@st.cache_data
def get_rendered_html(url):
    """
    Uses Selenium to render JavaScript content and retrieve the HTML source.

    Parameters:
    url (str): The URL to retrieve.

    Returns:
    str: The rendered HTML content.
    """
    # Set up Selenium WebDriver options
    options = Options()
    options.add_argument("--incognito")
    options.add_argument("--headless")  # Run in headless mode for Streamlit
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 "
        "Safari/537.36"
    )

    # Start WebDriver and get the URL
    service = Service(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())
    driver = webdriver.Chrome(service=service, options=options)
    driver.get(url)

    # Allow the page to load and render JavaScript
    time.sleep(3)

    # Get the page source after JavaScript execution
    html_content = driver.page_source

    # Close the WebDriver
    driver.quit()

    return html_content

def provide_download_buttons(information, url):
    """
    Provides download buttons for the extracted information.

    Parameters:
    information: The extracted information (DataFrame or list of DataFrames).
    url (str): The URL of the scraped website.
    """
    if 'support.apple' in url:
        excel_data = convert_df_to_excel(information)

        st.download_button(
            label="Download data as Excel",
            data=excel_data,
            file_name="apple_security_updates.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.success("File is ready for download!")

    elif 'chromereleases' in url:
        information['Link'] = url
        information = generate_unique_qr_codes(information, 'Link', 'QR Code')
        excel_data = convert_df_to_excel_with_qr(information, 'QR Code')

        st.download_button(
            label="Download data as Excel",
            data=excel_data,
            file_name="stable_channel_update_for_desktop.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.success("File is ready for download!")

    elif 'oracle.com' in url:
        combined_df = pd.concat(information, ignore_index=True)
        excel_data = convert_df_to_excel(combined_df)

        st.download_button(
            label="Download data as Excel",
            data=excel_data,
            file_name="oracle_security_tables.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.success("File is ready for download!")

    elif 'support.sap.com' in url:
        excel_data = convert_df_to_excel(information)

        st.download_button(
            label="Download data as Excel",
            data=excel_data,
            file_name="sap_security_table.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.success("File is ready for download!")

    elif 'fortiguard.com' in url:
        option_list = information['Date'].unique().tolist()
        options = st.multiselect(
            "Please select a date you would like to extract the data from:",
            option_list
        )

        if options:
            filtered_information = information[information['Date'].isin(options)]
            
            url_list = filtered_information["Link"].unique().tolist()
            
            df1, df2 = get_complete_fortinet_details(url_list)

            excel_data = convert_dfs_to_excel([df1, df2], ['DF1', 'DF2'])

            st.download_button(
                label="Download data as Excel",
                data=excel_data,
                file_name="fortinet_security_table.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

            if clicked:
                st.success("File is ready for download!")
                st.stop()
            

        
        else:
            st.info("Please select a date to export the data from.")

    else:
        st.error("Unsupported URL.")

# ------------------- Main Logic -------------------

if st.button("Scrape Site"):
    st.write("Scraping the website...")
    # Initialize the progress bar
    progress_text = "Operation in progress. Please wait."
    my_bar = st.progress(0, text=progress_text)

    try:
        # Update progress to 10%
        my_bar.progress(10, text=progress_text)

        # Scrape and render the website content using Selenium
        html_content = get_rendered_html(url)
        my_bar.progress(40, text=progress_text)

        # Parse the HTML with BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        my_bar.progress(60, text=progress_text)

        # Extract information using the appropriate function
        if "support.apple" in url:
            information = get_apple_details(soup)
        elif "chromereleases" in url:
            information = get_google_chrome_details(soup)
        elif 'oracle.com' in url:
            information = get_oracle_details(soup)
        elif 'support.sap.com' in url:
            information = get_sap_details(soup)
        elif 'fortiguard.com' in url:
            information = get_fortinet_details(soup)
        else:
            st.error("Unsupported URL.")
            information = None
        my_bar.progress(80, text=progress_text)

        if information is not None:
            # Store the scraped data in session state
            st.session_state.dom_content = information

            # Display the information in an expandable section
            with st.expander("View Content"):
                if isinstance(information, list):
                    for i, df in enumerate(information):
                        st.write(f"DataFrame {i+1} out of {len(information)}")
                        st.dataframe(df.reset_index(drop=True))
                else:
                    st.dataframe(information)
            st.success("Scraping completed successfully!")
        else:
            st.error("Failed to extract information from the URL.")
        my_bar.progress(100, text="Scraping completed.")

    except Exception as e:
        st.error(f"An error occurred: {e}")
        logging.exception("An error occurred during scraping.")
    finally:
        # Remove the progress bar after completion
        my_bar.empty()

# Check if content exists before showing download options
if "dom_content" in st.session_state and st.session_state.dom_content is not None:
    information = st.session_state.dom_content
    provide_download_buttons(information, url)
else:
    st.write("Enter a Website URL to begin scraping for information.")
